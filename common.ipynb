{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1c27274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S字母:1168=ryuwryuwryuwryuwEP',\n",
       " 'S小写:1668=六六七二六六七二六六七二六六七二EP',\n",
       " 'S数字:2899=11597159715971596E',\n",
       " 'S数字:4190=16761676167616760E']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vocab = {\n",
    "            'mark': list('PSEU'), # P:padding, S:start, E:end, U:unknow\n",
    "            'number': list('0123456789'),\n",
    "            'letter': list('pqwertyuio'),\n",
    "            'chinese_lower': list('〇一二三四五六七八九'),\n",
    "            'chinese_upper': list('零壹贰叁肆伍陆柒捌玖'),\n",
    "            'other': list('数字大写小母:=_'),\n",
    "        }\n",
    "\n",
    "        self.decoder = [l for vocab in self.vocab.values() for l in vocab]\n",
    "        self.encoder = {j: index for index, j in enumerate(self.decoder)}\n",
    "\n",
    "        self.label = {\n",
    "            'number': 0,\n",
    "            'letter': 1,\n",
    "            'chinese_lower': 2,\n",
    "            'chinese_upper': 3\n",
    "        }\n",
    "        self.prefix = ['数字', '字母', '小写', '大写']\n",
    "\n",
    "    def decode(self, x):\n",
    "        return ''.join([self.decoder[i] for i in x])\n",
    "\n",
    "    def get_data(self, prefix: bool) -> tuple[int, list[int]]:\n",
    "        # 生成:问题和答案\n",
    "        question = random.randint(1000, 9999)  # int 4110\n",
    "        answer = int(str(question) * 4) * 4 # int 16441644164416440\n",
    "        \n",
    "        question = list(str(question)) # ['4', '1', '1', '0']\n",
    "        answer = list(str(answer))  # ['1', '6', '4', '4', '1', '6', '4', '4', '1', '6', '4', '4', '1', '6', '4', '4', '0']\n",
    "\n",
    "        # 生成：标签\n",
    "        label = random.choice(list(self.label.keys())) # number, letter, chinese_lower, chinese_upper\n",
    "        label_id = self.label[label] # 0, 1, 2, 3\n",
    "\n",
    "        # 改写：答案(四种答案可以随机选择)\n",
    "        answer = [self.vocab[label][int(i)] for i in answer] # ['一', '六', '四', '四', '一', '六', '四', '四', '一', '六', '四', '四', '一', '六', '四', '四', '〇']\n",
    "\n",
    "        # 组合:问题和答案\n",
    "        if prefix:\n",
    "            prefix = list(self.prefix[label_id])\n",
    "        else:\n",
    "            prefix = list('__')\n",
    "        \n",
    "        tokens = prefix + [':'] + question + ['='] + answer # ['小', '写', ':', '4', '1', '1', '0', '=', '一', '六', '四', '四', '一', '六', '四', '四', '一', '六', '四', '四', '一', '六', '四', '四', '〇']\n",
    "\n",
    "        # 编码\n",
    "        token_ids = [self.encoder[t] for t in tokens]\n",
    "        token_ids = [self.encoder['S']] + token_ids + [self.encoder['E']]\n",
    "        # ['S', '小', '写', ':', '4', '1', '1', '0', '=', '一', '六', '四', '四', '一', '六', '四', '四', '一', '六', '四', '四', '一', '六', '四', '四', '〇', 'E']\n",
    "\n",
    "        return label_id, token_ids\n",
    "\n",
    "    def get_batch_data(self, prefix:bool, batch_size: int)->tuple[list, list, list]:\n",
    "        data = [self.get_data(prefix=prefix) for _ in range(batch_size)]\n",
    "\n",
    "        label = [i[0] for i in data]\n",
    "        token = [i[1] for i in data]\n",
    "\n",
    "        return label, *self.batch_pad(token=token)\n",
    "\n",
    "    def batch_pad(self, text=None, token=None):\n",
    "        if text:\n",
    "            #编码\n",
    "            token = [[self.encoder[j] for j in i] for i in text]\n",
    "\n",
    "        max_len_in_batch = max([len(i) for i in token])\n",
    "\n",
    "        input_ids = []\n",
    "        attention_mask = []\n",
    "        for i in token:\n",
    "            attention_mask.append([1] * len(i) + [0] * (max_len_in_batch - len(i)))\n",
    "            input_ids.append(i + [self.encoder['P']] * (max_len_in_batch - len(i)))\n",
    "\n",
    "        return input_ids, attention_mask\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# decode input_ids\n",
    "[tokenizer.decode(i) for i in tokenizer.get_batch_data(prefix=True, batch_size=4)[1]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60f86596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S__:7082=wieepieepieepiewiE',\n",
       " 'S__:8723=三四八九五四八九五四八九五四八九二E',\n",
       " 'S__:4814=qowtuowtuowtuowtyE',\n",
       " 'S__:1892=7568756875687568EP',\n",
       " 'S__:4539=18157815781578156E',\n",
       " 'S__:3460=13841384138413840E',\n",
       " 'S__:2402=玖陆零捌玖陆零捌玖陆零捌玖陆零捌EP',\n",
       " 'S__:2138=ittwittwittwittwEP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(i) for i in tokenizer.get_batch_data(prefix=False, batch_size=8)[1]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e242caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17208b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGEN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        from transformers import GPT2Config, GPT2Model\n",
    "\n",
    "        self.config = GPT2Config(bos_token_id=tokenizer.encoder['S'],\n",
    "                                 eos_token_id=tokenizer.encoder['E'],\n",
    "                                 n_embd=64,\n",
    "                                 n_head=4,\n",
    "                                 n_layer=4,\n",
    "                                 n_positions=128,\n",
    "                                 vocab_size=len(tokenizer.decoder))\n",
    "\n",
    "        self.feature = GPT2Model(self.config)\n",
    "\n",
    "        self.fc_out = torch.nn.Linear(64, self.config.vocab_size, bias=False)\n",
    "\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.feature(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask).last_hidden_state\n",
    "\n",
    "        return self.fc_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23b28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCLS(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        from transformers import BertConfig, BertModel\n",
    "\n",
    "        self.config = BertConfig(hidden_size=64,\n",
    "                                 intermediate_size=64,\n",
    "                                 max_position_embeddings=128,\n",
    "                                 num_attention_heads=4,\n",
    "                                 num_hidden_layers=4,\n",
    "                                 vocab_size=len(tokenizer.decoder))\n",
    "\n",
    "        self.feature = BertModel(self.config)\n",
    "\n",
    "        self.fc_out = torch.nn.Sequential(torch.nn.Dropout(p=0.1),\n",
    "                                          torch.nn.Linear(64, 4))\n",
    "\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.feature(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask).pooler_output\n",
    "\n",
    "        return self.fc_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6224a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPPO(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_gen):\n",
    "        super().__init__()\n",
    "        self.model_gen = model_gen\n",
    "        self.v_head = torch.nn.Sequential(torch.nn.Dropout(0.1),\n",
    "                                          torch.nn.Linear(64, 1))\n",
    "\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state = self.model_gen.feature(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True).last_hidden_state\n",
    "\n",
    "        logits = self.model_gen.fc_out(last_hidden_state)\n",
    "        value = self.v_head(last_hidden_state).squeeze(-1)\n",
    "\n",
    "        return logits, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13f60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generater = None\n",
    "\n",
    "\n",
    "def generate(model_gen, input_ids):\n",
    "    global generater\n",
    "    if not generater:\n",
    "        #包装类,用于生成\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        generater = GPT2LMHeadModel(model_gen.config)\n",
    "        generater.transformer = model_gen.feature\n",
    "        generater.lm_head = model_gen.fc_out\n",
    "        generater.to(device)\n",
    "\n",
    "    return generater.generate(input_ids=input_ids,\n",
    "                              min_length=-1,\n",
    "                              top_k=0.0,\n",
    "                              top_p=1.0,\n",
    "                              do_sample=True,\n",
    "                              pad_token_id=tokenizer.encoder['P'],\n",
    "                              max_new_tokens=25,\n",
    "                              eos_token_id=tokenizer.encoder['E'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu117-pt2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
